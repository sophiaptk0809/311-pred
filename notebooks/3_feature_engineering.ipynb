{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..')) \n",
    "processed_DPW_path = os.path.join(project_root, 'data', 'processed', 'DPW_data_r3y.csv')\n",
    "df = pd.read_csv(processed_DPW_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 40606 entries, 0 to 40605\n",
      "Data columns (total 30 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   _id                40606 non-null  int64  \n",
      " 1   group_id           40606 non-null  int64  \n",
      " 2   num_requests       40606 non-null  int64  \n",
      " 3   parent_closed      40606 non-null  object \n",
      " 4   status_name        40606 non-null  object \n",
      " 5   status_code        40606 non-null  int64  \n",
      " 6   dept               40606 non-null  object \n",
      " 7   request_type_name  40606 non-null  object \n",
      " 8   request_type_id    40606 non-null  int64  \n",
      " 9   create_date_et     40606 non-null  object \n",
      " 10  create_date_utc    40606 non-null  object \n",
      " 11  last_action_et     40606 non-null  object \n",
      " 12  last_action_utc    40606 non-null  object \n",
      " 13  closed_date_et     38598 non-null  object \n",
      " 14  closed_date_utc    38598 non-null  object \n",
      " 15  origin             40606 non-null  object \n",
      " 16  street             40052 non-null  object \n",
      " 17  cross_street       8630 non-null   object \n",
      " 18  street_id          40350 non-null  float64\n",
      " 19  cross_street_id    40350 non-null  float64\n",
      " 20  city               40606 non-null  object \n",
      " 21  neighborhood       40095 non-null  object \n",
      " 22  census_tract       10429 non-null  float64\n",
      " 23  council_district   40356 non-null  float64\n",
      " 24  ward               40115 non-null  float64\n",
      " 25  police_zone        40100 non-null  float64\n",
      " 26  latitude           40422 non-null  float64\n",
      " 27  longitude          40422 non-null  float64\n",
      " 28  geo_accuracy       40606 non-null  object \n",
      " 29  date               40606 non-null  object \n",
      "dtypes: float64(8), int64(5), object(17)\n",
      "memory usage: 9.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()\n",
    "date_columns = ['create_date_et', 'create_date_utc', 'last_action_et', \n",
    "                'last_action_utc', 'closed_date_et', 'closed_date_utc']\n",
    "\n",
    "for col in date_columns:\n",
    "    df[col] = pd.to_datetime(df[col])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cities: 17 unique values\n",
      "Pittsburgh: 40472 records (99.67%)\n",
      "Non-Pittsburgh: 134 records\n",
      "\n",
      "After filtering:\n",
      "Records: 40472 of 40606 (99.67%)\n",
      "Neighborhoods: 92 unique values\n",
      "Missing neighborhoods: 0 records\n",
      "\n",
      "Pittsburgh-only dataset ready\n"
     ]
    }
   ],
   "source": [
    "# Geographic Data Cleaning - Focus on Pittsburgh\n",
    "\n",
    "# 1. Analyze city distribution\n",
    "city_counts = df['city'].value_counts(dropna=False)\n",
    "print(f\"Cities: {len(city_counts)} unique values\")\n",
    "print(f\"Pittsburgh: {city_counts.get('Pittsburgh', 0)} records ({city_counts.get('Pittsburgh', 0)/len(df):.2%})\")\n",
    "print(f\"Non-Pittsburgh: {len(df) - city_counts.get('Pittsburgh', 0)} records\")\n",
    "\n",
    "# 2. Filter to Pittsburgh only\n",
    "df_pittsburgh = df[df['city'] == 'Pittsburgh'].copy()\n",
    "\n",
    "# 3. Validate cleaning\n",
    "neighborhood_counts = df_pittsburgh['neighborhood'].value_counts(dropna=False)\n",
    "print(f\"\\nAfter filtering:\")\n",
    "print(f\"Records: {len(df_pittsburgh)} of {len(df)} ({len(df_pittsburgh)/len(df):.2%})\")\n",
    "print(f\"Neighborhoods: {len(neighborhood_counts)} unique values\")\n",
    "print(f\"Missing neighborhoods: {neighborhood_counts.get(pd.NA, 0)} records\")\n",
    "\n",
    "# Complete\n",
    "print(\"\\nPittsburgh-only dataset ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date\n",
       "2025-01-21    496\n",
       "2025-01-22    487\n",
       "2024-01-17    384\n",
       "2025-01-15    313\n",
       "2025-01-16    260\n",
       "             ... \n",
       "2024-07-27      1\n",
       "2022-11-25      1\n",
       "2022-12-04      1\n",
       "2022-09-04      1\n",
       "2023-05-06      1\n",
       "Name: count, Length: 1072, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pittsburgh['date'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping unused columns...\n",
      "Original columns: 30\n",
      "Columns to drop: 22 of 22 specified\n",
      "Remaining columns: 8\n",
      "\n",
      "Remaining columns:\n",
      "['_id', 'status_name', 'dept', 'request_type_name', 'create_date_et', 'closed_date_et', 'origin', 'neighborhood']\n",
      "\n",
      "Creating final dataset with key features...\n",
      "Final dataset shape: (40472, 13)\n",
      "Final dataset size: 3.86 MB\n",
      "\n",
      "Final dataset preview:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>status_name</th>\n",
       "      <th>dept</th>\n",
       "      <th>request_type_name</th>\n",
       "      <th>create_date_et</th>\n",
       "      <th>closed_date_et</th>\n",
       "      <th>origin</th>\n",
       "      <th>neighborhood</th>\n",
       "      <th>resolution_time_days</th>\n",
       "      <th>hour</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>month</th>\n",
       "      <th>is_weekend</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>65</td>\n",
       "      <td>in progress</td>\n",
       "      <td>DPW - Street Maintenance</td>\n",
       "      <td>Litter, Public Property</td>\n",
       "      <td>2023-07-08 11:38:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>Website</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>86</td>\n",
       "      <td>closed</td>\n",
       "      <td>DPW - Street Maintenance</td>\n",
       "      <td>Trail Maintenance</td>\n",
       "      <td>2024-08-28 08:23:00</td>\n",
       "      <td>2024-12-26 12:45:00</td>\n",
       "      <td>Call Center</td>\n",
       "      <td>NaN</td>\n",
       "      <td>120.181944</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>177</td>\n",
       "      <td>closed</td>\n",
       "      <td>DPW - Street Maintenance</td>\n",
       "      <td>Street Cleaning/Sweeping</td>\n",
       "      <td>2024-09-05 09:41:00</td>\n",
       "      <td>2024-09-27 06:35:00</td>\n",
       "      <td>Call Center</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21.870833</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>454</td>\n",
       "      <td>closed</td>\n",
       "      <td>DPW - Street Maintenance</td>\n",
       "      <td>Trail Maintenance</td>\n",
       "      <td>2024-08-06 11:35:00</td>\n",
       "      <td>2024-12-26 12:51:00</td>\n",
       "      <td>Call Center</td>\n",
       "      <td>NaN</td>\n",
       "      <td>142.052778</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>669</td>\n",
       "      <td>open</td>\n",
       "      <td>DPW - Street Maintenance</td>\n",
       "      <td>Litter, Public Property</td>\n",
       "      <td>2023-05-22 10:12:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>Website</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40601</th>\n",
       "      <td>815667</td>\n",
       "      <td>closed</td>\n",
       "      <td>DPW - Street Maintenance</td>\n",
       "      <td>Potholes</td>\n",
       "      <td>2025-02-01 10:09:00</td>\n",
       "      <td>2025-02-03 04:14:00</td>\n",
       "      <td>Call Center</td>\n",
       "      <td>South Side Slopes</td>\n",
       "      <td>1.753472</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40602</th>\n",
       "      <td>815670</td>\n",
       "      <td>open</td>\n",
       "      <td>DPW - Street Maintenance</td>\n",
       "      <td>Potholes</td>\n",
       "      <td>2025-02-02 16:47:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>Report2Gov Website</td>\n",
       "      <td>South Side Flats</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40603</th>\n",
       "      <td>815674</td>\n",
       "      <td>open</td>\n",
       "      <td>DPW - Street Maintenance</td>\n",
       "      <td>Litter, Public Property</td>\n",
       "      <td>2025-02-01 08:37:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>Website</td>\n",
       "      <td>Brookline</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40604</th>\n",
       "      <td>815678</td>\n",
       "      <td>open</td>\n",
       "      <td>DPW - Street Maintenance</td>\n",
       "      <td>Drainage/Leak</td>\n",
       "      <td>2025-02-01 21:08:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>Website</td>\n",
       "      <td>Brookline</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40605</th>\n",
       "      <td>815687</td>\n",
       "      <td>open</td>\n",
       "      <td>DPW - Street Maintenance</td>\n",
       "      <td>Litter, Public Property</td>\n",
       "      <td>2025-02-03 13:49:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>Report2Gov Website</td>\n",
       "      <td>Mount Washington</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40472 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          _id  status_name                      dept  \\\n",
       "0          65  in progress  DPW - Street Maintenance   \n",
       "1          86       closed  DPW - Street Maintenance   \n",
       "2         177       closed  DPW - Street Maintenance   \n",
       "3         454       closed  DPW - Street Maintenance   \n",
       "4         669         open  DPW - Street Maintenance   \n",
       "...       ...          ...                       ...   \n",
       "40601  815667       closed  DPW - Street Maintenance   \n",
       "40602  815670         open  DPW - Street Maintenance   \n",
       "40603  815674         open  DPW - Street Maintenance   \n",
       "40604  815678         open  DPW - Street Maintenance   \n",
       "40605  815687         open  DPW - Street Maintenance   \n",
       "\n",
       "              request_type_name      create_date_et      closed_date_et  \\\n",
       "0       Litter, Public Property 2023-07-08 11:38:00                 NaT   \n",
       "1             Trail Maintenance 2024-08-28 08:23:00 2024-12-26 12:45:00   \n",
       "2      Street Cleaning/Sweeping 2024-09-05 09:41:00 2024-09-27 06:35:00   \n",
       "3             Trail Maintenance 2024-08-06 11:35:00 2024-12-26 12:51:00   \n",
       "4       Litter, Public Property 2023-05-22 10:12:00                 NaT   \n",
       "...                         ...                 ...                 ...   \n",
       "40601                  Potholes 2025-02-01 10:09:00 2025-02-03 04:14:00   \n",
       "40602                  Potholes 2025-02-02 16:47:00                 NaT   \n",
       "40603   Litter, Public Property 2025-02-01 08:37:00                 NaT   \n",
       "40604             Drainage/Leak 2025-02-01 21:08:00                 NaT   \n",
       "40605   Litter, Public Property 2025-02-03 13:49:00                 NaT   \n",
       "\n",
       "                   origin       neighborhood  resolution_time_days  hour  \\\n",
       "0                 Website                NaN                   NaN    11   \n",
       "1             Call Center                NaN            120.181944     8   \n",
       "2             Call Center                NaN             21.870833     9   \n",
       "3             Call Center                NaN            142.052778    11   \n",
       "4                 Website                NaN                   NaN    10   \n",
       "...                   ...                ...                   ...   ...   \n",
       "40601         Call Center  South Side Slopes              1.753472    10   \n",
       "40602  Report2Gov Website   South Side Flats                   NaN    16   \n",
       "40603             Website          Brookline                   NaN     8   \n",
       "40604             Website          Brookline                   NaN    21   \n",
       "40605  Report2Gov Website   Mount Washington                   NaN    13   \n",
       "\n",
       "       day_of_week  month  is_weekend  \n",
       "0                5      7           1  \n",
       "1                2      8           0  \n",
       "2                3      9           0  \n",
       "3                1      8           0  \n",
       "4                0      5           0  \n",
       "...            ...    ...         ...  \n",
       "40601            5      2           1  \n",
       "40602            6      2           1  \n",
       "40603            5      2           1  \n",
       "40604            5      2           1  \n",
       "40605            0      2           0  \n",
       "\n",
       "[40472 rows x 13 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fix the column dropping code\n",
    "print(\"Dropping unused columns...\")\n",
    "print(f\"Original columns: {len(df_pittsburgh.columns)}\")\n",
    "\n",
    "unused_columns = ['create_date_utc', 'last_action_et', 'last_action_utc', 'closed_date_utc', 'status_code',\n",
    "                  'group_id', 'num_requests', 'parent_closed', 'request_type_id', \n",
    "                  'street', 'cross_street', 'street_id', 'cross_street_id', 'city',\n",
    "                  'census_tract', 'council_district', 'ward', 'police_zone', \n",
    "                  'latitude', 'longitude', 'geo_accuracy', 'date']\n",
    "\n",
    "# Check which columns actually exist in the dataframe\n",
    "columns_to_drop = [col for col in unused_columns if col in df_pittsburgh.columns]\n",
    "print(f\"Columns to drop: {len(columns_to_drop)} of {len(unused_columns)} specified\")\n",
    "\n",
    "# Drop the columns\n",
    "df_clean = df_pittsburgh.drop(columns=columns_to_drop)\n",
    "print(f\"Remaining columns: {len(df_clean.columns)}\")\n",
    "\n",
    "# Show remaining columns\n",
    "print(\"\\nRemaining columns:\")\n",
    "print(df_clean.columns.tolist())\n",
    "\n",
    "# Create a final clean dataset with selected features\n",
    "print(\"\\nCreating final dataset with key features...\")\n",
    "\n",
    "# Calculate any needed derived fields\n",
    "if 'create_date_et' in df_clean.columns and 'closed_date_et' in df_clean.columns:\n",
    "    df_clean['resolution_time_days'] = (df_clean['closed_date_et'] - df_clean['create_date_et']).dt.total_seconds() / (24*60*60)\n",
    "\n",
    "# Create derived temporal features\n",
    "if 'create_date_et' in df_clean.columns:\n",
    "    df_clean['hour'] = df_clean['create_date_et'].dt.hour\n",
    "    df_clean['day_of_week'] = df_clean['create_date_et'].dt.dayofweek  # 0=Monday, 6=Sunday\n",
    "    df_clean['month'] = df_clean['create_date_et'].dt.month\n",
    "    df_clean['is_weekend'] = df_clean['day_of_week'].apply(lambda x: 1 if x >= 5 else 0)\n",
    "\n",
    "# Final dataset info\n",
    "print(f\"Final dataset shape: {df_clean.shape}\")\n",
    "print(f\"Final dataset size: {df_clean.memory_usage().sum() / 1048576:.2f} MB\")\n",
    "\n",
    "# Preview\n",
    "print(\"\\nFinal dataset preview:\")\n",
    "df_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After cross tab check and count of each neighbor in city outside Pittsburgh, we decide to **remove all the city outside of Pittsburgh** because:\n",
    "\n",
    "1. The data is heavily Pittsburgh-centric, with 277,639 requests from Pittsburgh compared to only a few hundred from other cities\n",
    "2. Other cities have very few neighborhoods (most have 0-1 neighborhoods) and sparse data\n",
    "3. The neighborhood information is most complete and meaningful for Pittsburgh, with 91 distinct neighborhoods\n",
    "4. Including other cities would create data imbalance and potentially introduce noise in the analysis\n",
    "5. The small sample sizes from other cities (ranging from 1-258 requests) make their data statistically less reliable\n",
    "\n",
    "This decision would help focus the analysis on Pittsburgh's data, which is more comprehensive and representative of the service request patterns we want to analyze."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['_id', 'group_id', 'num_requests', 'parent_closed', 'status_name',\n",
       "       'status_code', 'dept', 'request_type_name', 'request_type_id',\n",
       "       'create_date_et', 'create_date_utc', 'last_action_et',\n",
       "       'last_action_utc', 'closed_date_et', 'closed_date_utc', 'origin',\n",
       "       'street', 'cross_street', 'street_id', 'cross_street_id', 'city',\n",
       "       'neighborhood', 'census_tract', 'council_district', 'ward',\n",
       "       'police_zone', 'latitude', 'longitude', 'geo_accuracy', 'date'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>create_date_et</th>\n",
       "      <th>request_type_name</th>\n",
       "      <th>neighborhood</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>40562</th>\n",
       "      <td>815578</td>\n",
       "      <td>2025-02-04 14:04:00</td>\n",
       "      <td>Port A Potty</td>\n",
       "      <td>Squirrel Hill South</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40572</th>\n",
       "      <td>815592</td>\n",
       "      <td>2025-02-04 13:59:00</td>\n",
       "      <td>Litter Can, Public</td>\n",
       "      <td>Shadyside</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40551</th>\n",
       "      <td>815559</td>\n",
       "      <td>2025-02-04 13:37:00</td>\n",
       "      <td>Potholes</td>\n",
       "      <td>Squirrel Hill North</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40544</th>\n",
       "      <td>815544</td>\n",
       "      <td>2025-02-04 13:35:00</td>\n",
       "      <td>Potholes</td>\n",
       "      <td>Shadyside</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40589</th>\n",
       "      <td>815632</td>\n",
       "      <td>2025-02-04 12:30:00</td>\n",
       "      <td>Potholes</td>\n",
       "      <td>Bloomfield</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40588</th>\n",
       "      <td>815630</td>\n",
       "      <td>2025-02-04 07:37:00</td>\n",
       "      <td>Potholes</td>\n",
       "      <td>Bloomfield</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40563</th>\n",
       "      <td>815579</td>\n",
       "      <td>2025-02-03 22:22:00</td>\n",
       "      <td>Potholes</td>\n",
       "      <td>Squirrel Hill North</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40592</th>\n",
       "      <td>815636</td>\n",
       "      <td>2025-02-03 21:11:00</td>\n",
       "      <td>Potholes</td>\n",
       "      <td>Bloomfield</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40590</th>\n",
       "      <td>815634</td>\n",
       "      <td>2025-02-03 21:09:00</td>\n",
       "      <td>Potholes</td>\n",
       "      <td>Bloomfield</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40553</th>\n",
       "      <td>815564</td>\n",
       "      <td>2025-02-03 19:42:00</td>\n",
       "      <td>Potholes</td>\n",
       "      <td>Squirrel Hill South</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          _id      create_date_et   request_type_name         neighborhood\n",
       "40562  815578 2025-02-04 14:04:00        Port A Potty  Squirrel Hill South\n",
       "40572  815592 2025-02-04 13:59:00  Litter Can, Public            Shadyside\n",
       "40551  815559 2025-02-04 13:37:00            Potholes  Squirrel Hill North\n",
       "40544  815544 2025-02-04 13:35:00            Potholes            Shadyside\n",
       "40589  815632 2025-02-04 12:30:00            Potholes           Bloomfield\n",
       "40588  815630 2025-02-04 07:37:00            Potholes           Bloomfield\n",
       "40563  815579 2025-02-03 22:22:00            Potholes  Squirrel Hill North\n",
       "40592  815636 2025-02-03 21:11:00            Potholes           Bloomfield\n",
       "40590  815634 2025-02-03 21:09:00            Potholes           Bloomfield\n",
       "40553  815564 2025-02-03 19:42:00            Potholes  Squirrel Hill South"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['_id','create_date_et','request_type_name','neighborhood']].sort_values(by='create_date_et', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1072\n",
      "65\n",
      "91\n"
     ]
    }
   ],
   "source": [
    "print((df['create_date_et'].max() - df['create_date_et'].min()).days)\n",
    "print(df['request_type_name'].nunique())\n",
    "print(df['neighborhood'].nunique())\n",
    "\n",
    "## 3. Data Preprocessing - Feature Engineering\n",
    "### 3.1 Feature Engineering\n",
    "#### 3.1.1 Create a new column for the request type\n",
    "\n",
    "### DROP NA neighborhood\n",
    "df = df[df['neighborhood'].notna()]\n",
    "\n",
    "### DROP NA request type\n",
    "df = df[df['request_type_name'].notna()]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_7/j6gsg7kd1vxgq31_w637bnh00000gn/T/ipykernel_20936/1703100850.py:4: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  all_dates = pd.date_range(start=start_date, end=end_date, freq='H')\n"
     ]
    }
   ],
   "source": [
    "# Create date range\n",
    "start_date = df['create_date_et'].min()\n",
    "end_date = df['create_date_et'].max()\n",
    "all_dates = pd.date_range(start=start_date, end=end_date, freq='H')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_7/j6gsg7kd1vxgq31_w637bnh00000gn/T/ipykernel_20936/1885268575.py:6: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  all_dates = pd.date_range(start=start_date, end=end_date, freq='H')\n"
     ]
    }
   ],
   "source": [
    "# 1. First create the full cartesian product of all possible combinations\n",
    "\n",
    "# Create date range\n",
    "start_date = df['create_date_et'].min()\n",
    "end_date = df['create_date_et'].min() + pd.Timedelta(days=365)\n",
    "all_dates = pd.date_range(start=start_date, end=end_date, freq='H')\n",
    "\n",
    "# Get unique values\n",
    "neighborhoods = df['neighborhood'].unique()\n",
    "hours = range(24)\n",
    "\n",
    "# Create all possible combinations\n",
    "combinations = list(product(all_dates, neighborhoods))\n",
    "\n",
    "# Create the base dataframe\n",
    "matrix_df = pd.DataFrame(combinations, columns=['datetime', 'neighborhood'])\n",
    "\n",
    "# Extract date and hour\n",
    "matrix_df['date'] = matrix_df['datetime'].dt.date\n",
    "matrix_df['hour'] = matrix_df['datetime'].dt.hour\n",
    "\n",
    "# Create the target variable\n",
    "# First group the original data\n",
    "df['datetime'] = pd.to_datetime(df['create_date_et'])\n",
    "df['date'] = df['datetime'].dt.date\n",
    "df['hour'] = df['datetime'].dt.hour\n",
    "\n",
    "# Create a mapping of existing combinations\n",
    "existing_requests = df.groupby(['date', 'hour', 'neighborhood',]).size().reset_index()\n",
    "existing_requests['Y'] = 1\n",
    "\n",
    "# Merge with the full matrix\n",
    "matrix_df = matrix_df.merge(\n",
    "    existing_requests[['date', 'hour', 'neighborhood', 'Y']],\n",
    "    how='left',\n",
    "    left_on=['date', 'hour', 'neighborhood'],\n",
    "    right_on=['date', 'hour', 'neighborhood']\n",
    ")\n",
    "\n",
    "# Fill missing values with 0 (no request)\n",
    "matrix_df['Y'] = matrix_df['Y'].fillna(0)\n",
    "\n",
    "# Final columns organization\n",
    "final_matrix = matrix_df[['Y', 'date', 'hour', 'neighborhood']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Y</th>\n",
       "      <th>date</th>\n",
       "      <th>hour</th>\n",
       "      <th>neighborhood</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2022-02-28</td>\n",
       "      <td>0</td>\n",
       "      <td>Highland Park</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2022-02-28</td>\n",
       "      <td>0</td>\n",
       "      <td>Brookline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2022-02-28</td>\n",
       "      <td>0</td>\n",
       "      <td>Strip District</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2022-02-28</td>\n",
       "      <td>0</td>\n",
       "      <td>East Liberty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2022-02-28</td>\n",
       "      <td>0</td>\n",
       "      <td>New Homestead</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2022-02-28</td>\n",
       "      <td>0</td>\n",
       "      <td>Bloomfield</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2022-02-28</td>\n",
       "      <td>0</td>\n",
       "      <td>Crawford-Roberts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2022-02-28</td>\n",
       "      <td>0</td>\n",
       "      <td>Duquesne Heights</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2022-02-28</td>\n",
       "      <td>0</td>\n",
       "      <td>Mount Washington</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2022-02-28</td>\n",
       "      <td>0</td>\n",
       "      <td>Middle Hill</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Y        date  hour      neighborhood\n",
       "0  0.0  2022-02-28     0     Highland Park\n",
       "1  0.0  2022-02-28     0         Brookline\n",
       "2  0.0  2022-02-28     0    Strip District\n",
       "3  0.0  2022-02-28     0      East Liberty\n",
       "4  0.0  2022-02-28     0     New Homestead\n",
       "5  0.0  2022-02-28     0        Bloomfield\n",
       "6  0.0  2022-02-28     0  Crawford-Roberts\n",
       "7  0.0  2022-02-28     0  Duquesne Heights\n",
       "8  0.0  2022-02-28     0  Mount Washington\n",
       "9  0.0  2022-02-28     0       Middle Hill"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_matrix.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Y</th>\n",
       "      <th>date</th>\n",
       "      <th>hour</th>\n",
       "      <th>neighborhood</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2022-02-28</td>\n",
       "      <td>0</td>\n",
       "      <td>Point Breeze</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2022-02-28</td>\n",
       "      <td>1</td>\n",
       "      <td>Point Breeze</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2022-02-28</td>\n",
       "      <td>2</td>\n",
       "      <td>Point Breeze</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2022-02-28</td>\n",
       "      <td>3</td>\n",
       "      <td>Point Breeze</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2022-02-28</td>\n",
       "      <td>4</td>\n",
       "      <td>Point Breeze</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2022-02-28</td>\n",
       "      <td>5</td>\n",
       "      <td>Point Breeze</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>590</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2022-02-28</td>\n",
       "      <td>6</td>\n",
       "      <td>Point Breeze</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>681</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2022-02-28</td>\n",
       "      <td>7</td>\n",
       "      <td>Point Breeze</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>772</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2022-02-28</td>\n",
       "      <td>8</td>\n",
       "      <td>Point Breeze</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>863</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2022-02-28</td>\n",
       "      <td>9</td>\n",
       "      <td>Point Breeze</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Y        date  hour  neighborhood\n",
       "44   0.0  2022-02-28     0  Point Breeze\n",
       "135  0.0  2022-02-28     1  Point Breeze\n",
       "226  0.0  2022-02-28     2  Point Breeze\n",
       "317  0.0  2022-02-28     3  Point Breeze\n",
       "408  0.0  2022-02-28     4  Point Breeze\n",
       "499  0.0  2022-02-28     5  Point Breeze\n",
       "590  0.0  2022-02-28     6  Point Breeze\n",
       "681  0.0  2022-02-28     7  Point Breeze\n",
       "772  1.0  2022-02-28     8  Point Breeze\n",
       "863  0.0  2022-02-28     9  Point Breeze"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_matrix[final_matrix['neighborhood'] == 'Point Breeze'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neighborhood\n",
       "Highland Park    8761\n",
       "Bluff            8761\n",
       "Friendship       8761\n",
       "Overbrook        8761\n",
       "North Oakland    8761\n",
       "                 ... \n",
       "Manchester       8761\n",
       "North Shore      8761\n",
       "Bon Air          8761\n",
       "Morningside      8761\n",
       "Esplen           8761\n",
       "Name: count, Length: 91, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_matrix['neighborhood'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ML model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Basic Regression - Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_7/j6gsg7kd1vxgq31_w637bnh00000gn/T/ipykernel_20936/3960771655.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_matrix['date'] = pd.to_datetime(final_matrix['date'])\n",
      "/var/folders/_7/j6gsg7kd1vxgq31_w637bnh00000gn/T/ipykernel_20936/3960771655.py:42: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train[numeric_features] = scaler.fit_transform(X_train[numeric_features])\n",
      "/var/folders/_7/j6gsg7kd1vxgq31_w637bnh00000gn/T/ipykernel_20936/3960771655.py:43: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test[numeric_features] = scaler.transform(X_test[numeric_features])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Logistic Regression model...\n",
      "Logistic Regression Performance:\n",
      "Accuracy: 0.9874\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Top 10 Features with Positive Effect:\n",
      "                                   Feature  Coefficient\n",
      "18                  neighborhood_Brookline     1.700139\n",
      "14                 neighborhood_Bloomfield     1.601525\n",
      "82        neighborhood_Squirrel Hill South     1.451701\n",
      "20                    neighborhood_Carrick     1.414192\n",
      "73                  neighborhood_Shadyside     1.284970\n",
      "21  neighborhood_Central Business District     1.201808\n",
      "78          neighborhood_South Side Slopes     1.144382\n",
      "68               neighborhood_Point Breeze     1.056414\n",
      "77           neighborhood_South Side Flats     1.034579\n",
      "44              neighborhood_Highland Park     1.006675\n",
      "\n",
      "Top 10 Features with Negative Effect:\n",
      "                              Feature  Coefficient\n",
      "76           neighborhood_South Shore    -0.874970\n",
      "35                neighborhood_Esplen    -0.885610\n",
      "72             neighborhood_Ridgemont    -0.939045\n",
      "25        neighborhood_Chartiers City    -0.960490\n",
      "83             neighborhood_St. Clair    -0.960509\n",
      "31         neighborhood_East Carnegie    -0.971262\n",
      "40            neighborhood_Glen Hazel    -1.025212\n",
      "57  neighborhood_Mount Oliver Borough    -1.036046\n",
      "9      neighborhood_Arlington Heights    -1.036046\n",
      "3                          is_weekend    -1.374202\n",
      "\n",
      "Sample Predictions:\n",
      "Probability of request in Downtown at 8am: 0.0135\n",
      "Probability of request in South Side Flats at 11pm: 0.0136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sophiakuo/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score, precision_recall_fscore_support\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 1. Feature Engineering (same as before)\n",
    "final_matrix['date'] = pd.to_datetime(final_matrix['date'])\n",
    "final_matrix['day_of_week'] = final_matrix['date'].dt.dayofweek\n",
    "final_matrix['month'] = final_matrix['date'].dt.month\n",
    "final_matrix['is_weekend'] = final_matrix['day_of_week'].apply(lambda x: 1 if x >= 5 else 0)\n",
    "final_matrix['season'] = final_matrix['month'].apply(lambda x: \n",
    "                                                   0 if x in [12, 1, 2] else  # Winter\n",
    "                                                   1 if x in [3, 4, 5] else   # Spring\n",
    "                                                   2 if x in [6, 7, 8] else   # Summer\n",
    "                                                   3)                         # Fall\n",
    "\n",
    "# 2. One-hot encode neighborhoods\n",
    "neighborhoods_encoded = pd.get_dummies(final_matrix['neighborhood'], prefix='neighborhood')\n",
    "\n",
    "# 3. Combine features\n",
    "X = pd.concat([\n",
    "    final_matrix[['hour', 'day_of_week', 'month', 'is_weekend', 'season']],\n",
    "    neighborhoods_encoded\n",
    "], axis=1)\n",
    "\n",
    "y = final_matrix['Y']\n",
    "\n",
    "# 4. Train-test split (time-based)\n",
    "final_matrix_sorted = final_matrix.sort_values(by='date')\n",
    "split_index = int(len(final_matrix_sorted) * 0.8)\n",
    "\n",
    "X_train = X.iloc[:split_index]\n",
    "X_test = X.iloc[split_index:]\n",
    "y_train = y.iloc[:split_index]\n",
    "y_test = y.iloc[split_index:]\n",
    "\n",
    "# 5. Standardize numeric features (important for logistic regression)\n",
    "scaler = StandardScaler()\n",
    "numeric_features = ['hour', 'day_of_week', 'month', 'season']\n",
    "X_train[numeric_features] = scaler.fit_transform(X_train[numeric_features])\n",
    "X_test[numeric_features] = scaler.transform(X_test[numeric_features])\n",
    "\n",
    "# 6. Train logistic regression model\n",
    "print(\"Training Logistic Regression model...\")\n",
    "model = LogisticRegression(max_iter=1000, C=0.1, random_state=42)  # C is inverse regularization strength\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 7. Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_proba = model.predict_proba(X_test)[:, 1]  # Probability of class 1\n",
    "\n",
    "# 8. Evaluate model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(y_test, y_pred, average='binary')\n",
    "\n",
    "print(f\"Logistic Regression Performance:\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "\n",
    "# 9. Feature importance (coefficients)\n",
    "feature_importance = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'Coefficient': model.coef_[0]\n",
    "}).sort_values('Coefficient', ascending=False)\n",
    "\n",
    "print(\"\\nTop 10 Features with Positive Effect:\")\n",
    "print(feature_importance.head(10))\n",
    "\n",
    "print(\"\\nTop 10 Features with Negative Effect:\")\n",
    "print(feature_importance.tail(10))\n",
    "\n",
    "# 10. Sample prediction function (similar to before)\n",
    "def predict_request_probability(neighborhood, date_str, hour):\n",
    "    date = pd.to_datetime(date_str)\n",
    "    features = {\n",
    "        'hour': hour,\n",
    "        'day_of_week': date.dayofweek,\n",
    "        'month': date.month,\n",
    "        'is_weekend': 1 if date.dayofweek >= 5 else 0,\n",
    "        'season': 0 if date.month in [12, 1, 2] else \n",
    "                 1 if date.month in [3, 4, 5] else\n",
    "                 2 if date.month in [6, 7, 8] else 3\n",
    "    }\n",
    "    \n",
    "    # Add neighborhood encoding\n",
    "    for col in neighborhoods_encoded.columns:\n",
    "        features[col] = 1 if col == f'neighborhood_{neighborhood}' else 0\n",
    "    \n",
    "    # Create DataFrame\n",
    "    sample = pd.DataFrame([features])\n",
    "    \n",
    "    # Scale numeric features\n",
    "    sample[numeric_features] = scaler.transform(sample[numeric_features])\n",
    "    \n",
    "    # Get columns in right order\n",
    "    sample = sample[X.columns]\n",
    "    \n",
    "    # Predict\n",
    "    return model.predict_proba(sample)[0][1]\n",
    "\n",
    "# Example predictions\n",
    "print(\"\\nSample Predictions:\")\n",
    "print(f\"Probability of request in Downtown at 8am: {predict_request_probability('Central Business District', '2023-04-01', 8):.4f}\")\n",
    "print(f\"Probability of request in South Side Flats at 11pm: {predict_request_probability('South Side Flats', '2023-04-02', 23):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Balanced RF model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Balanced Random Forest model...\n",
      "Balanced RF Performance:\n",
      "Accuracy: 0.9725\n",
      "Precision: 0.0592\n",
      "Recall: 0.0789\n",
      "F1 Score: 0.0677\n",
      "\n",
      "Sample Predictions:\n",
      "Probability of request in Downtown tomorrow at 8am: 0.0053\n",
      "Probability of request in South Side Flats on weekend at 11pm: 0.0221\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score, precision_recall_fscore_support\n",
    "from datetime import datetime\n",
    "\n",
    "# 1. Feature Engineering\n",
    "# Convert date to datetime and extract useful features\n",
    "final_matrix['date'] = pd.to_datetime(final_matrix['date'])\n",
    "final_matrix['day_of_week'] = final_matrix['date'].dt.dayofweek  # 0=Monday, 6=Sunday\n",
    "final_matrix['month'] = final_matrix['date'].dt.month\n",
    "final_matrix['is_weekend'] = final_matrix['day_of_week'].apply(lambda x: 1 if x >= 5 else 0)\n",
    "final_matrix['season'] = final_matrix['month'].apply(lambda x: \n",
    "                                                   0 if x in [12, 1, 2] else  # Winter\n",
    "                                                   1 if x in [3, 4, 5] else   # Spring\n",
    "                                                   2 if x in [6, 7, 8] else   # Summer\n",
    "                                                   3)                         # Fall\n",
    "\n",
    "# 2. Encode categorical variables\n",
    "# One-hot encode neighborhoods\n",
    "neighborhoods_encoded = pd.get_dummies(final_matrix['neighborhood'], prefix='neighborhood')\n",
    "\n",
    "# 3. Combine features\n",
    "X = pd.concat([\n",
    "    final_matrix[['hour', 'day_of_week', 'month', 'is_weekend', 'season']],\n",
    "    neighborhoods_encoded\n",
    "], axis=1)\n",
    "\n",
    "y = final_matrix['Y']\n",
    "\n",
    "# 4. Train-test split (with time-based split)\n",
    "# Sort by date to maintain time order\n",
    "final_matrix_sorted = final_matrix.sort_values(by='date')\n",
    "split_index = int(len(final_matrix_sorted) * 0.8)  # 80% train, 20% test\n",
    "\n",
    "X_train = X.iloc[:split_index]\n",
    "X_test = X.iloc[split_index:]\n",
    "y_train = y.iloc[:split_index]\n",
    "y_test = y.iloc[split_index:]\n",
    "\n",
    "# 5. Train model\n",
    "#  Use class weights for Random Forest\n",
    "print(\"Training Balanced Random Forest model...\")\n",
    "balanced_rf = RandomForestClassifier(\n",
    "    n_estimators=100, \n",
    "    class_weight='balanced',  # Add class weights\n",
    "    random_state=42, \n",
    "    n_jobs=-1\n",
    ")\n",
    "balanced_rf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_balanced = balanced_rf.predict(X_test)\n",
    "\n",
    "# Evaluate model\n",
    "balanced_accuracy = accuracy_score(y_test, y_pred_balanced)\n",
    "balanced_precision, balanced_recall, balanced_f1, _ = precision_recall_fscore_support(\n",
    "    y_test, y_pred_balanced, average='binary'\n",
    ")\n",
    "\n",
    "print(f\"Balanced RF Performance:\")\n",
    "print(f\"Accuracy: {balanced_accuracy:.4f}\")\n",
    "print(f\"Precision: {balanced_precision:.4f}\")\n",
    "print(f\"Recall: {balanced_recall:.4f}\")\n",
    "print(f\"F1 Score: {balanced_f1:.4f}\")\n",
    "\n",
    "\n",
    "# 9. Create a sample prediction function\n",
    "def predict_request_probability(neighborhood, date_str, hour):\n",
    "    \"\"\"Predict probability of request for a given neighborhood, date and hour\"\"\"\n",
    "    # Parse date\n",
    "    date = pd.to_datetime(date_str)\n",
    "    \n",
    "    # Create feature row\n",
    "    features = {\n",
    "        'hour': hour,\n",
    "        'day_of_week': date.dayofweek,\n",
    "        'month': date.month,\n",
    "        'is_weekend': 1 if date.dayofweek >= 5 else 0,\n",
    "        'season': 0 if date.month in [12, 1, 2] else \n",
    "                 1 if date.month in [3, 4, 5] else\n",
    "                 2 if date.month in [6, 7, 8] else 3\n",
    "    }\n",
    "    \n",
    "    # Add neighborhood one-hot encoding\n",
    "    for col in neighborhoods_encoded.columns:\n",
    "        features[col] = 1 if col == f'neighborhood_{neighborhood}' else 0\n",
    "    \n",
    "    # Create DataFrame with single row\n",
    "    sample = pd.DataFrame([features])\n",
    "    \n",
    "    # Get columns in right order\n",
    "    sample = sample[X.columns]\n",
    "    \n",
    "    # Predict\n",
    "    return model.predict_proba(sample)[0][1]  # Probability of class 1\n",
    "\n",
    "# Example prediction\n",
    "print(\"\\nSample Predictions:\")\n",
    "print(f\"Probability of request in Downtown tomorrow at 8am: {predict_request_probability('Central Business District', '2023-04-01', 8):.4f}\")\n",
    "print(f\"Probability of request in South Side Flats on weekend at 11pm: {predict_request_probability('South Side Flats', '2023-04-02', 23):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Balanced RF + SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying SMOTE oversampling...\n",
      "Class distribution after SMOTE:\n",
      "Class 0 (no request): 627433\n",
      "Class 1 (request): 627433\n",
      "Ratio: 0.50\n",
      "\n",
      "Training RF with SMOTE data...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 22\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mTraining RF with SMOTE data...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     16\u001b[0m rf_smote \u001b[38;5;241m=\u001b[39m RandomForestClassifier(\n\u001b[1;32m     17\u001b[0m     n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m,\n\u001b[1;32m     18\u001b[0m     random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m,\n\u001b[1;32m     19\u001b[0m     n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;66;03m# No class_weight needed since SMOTE already balanced the classes\u001b[39;00m\n\u001b[1;32m     21\u001b[0m )\n\u001b[0;32m---> 22\u001b[0m rf_smote\u001b[38;5;241m.\u001b[39mfit(X_train_smote, y_train_smote)\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# Make predictions\u001b[39;00m\n\u001b[1;32m     25\u001b[0m y_pred_smote \u001b[38;5;241m=\u001b[39m rf_smote\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/sklearn/base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1471\u001b[0m     )\n\u001b[1;32m   1472\u001b[0m ):\n\u001b[0;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/sklearn/ensemble/_forest.py:489\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    478\u001b[0m trees \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    479\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_estimator(append\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[1;32m    480\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_more_estimators)\n\u001b[1;32m    481\u001b[0m ]\n\u001b[1;32m    483\u001b[0m \u001b[38;5;66;03m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[1;32m    484\u001b[0m \u001b[38;5;66;03m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[1;32m    485\u001b[0m \u001b[38;5;66;03m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[1;32m    486\u001b[0m \u001b[38;5;66;03m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[1;32m    487\u001b[0m \u001b[38;5;66;03m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[1;32m    488\u001b[0m \u001b[38;5;66;03m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[0;32m--> 489\u001b[0m trees \u001b[38;5;241m=\u001b[39m Parallel(\n\u001b[1;32m    490\u001b[0m     n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs,\n\u001b[1;32m    491\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose,\n\u001b[1;32m    492\u001b[0m     prefer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthreads\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    493\u001b[0m )(\n\u001b[1;32m    494\u001b[0m     delayed(_parallel_build_trees)(\n\u001b[1;32m    495\u001b[0m         t,\n\u001b[1;32m    496\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbootstrap,\n\u001b[1;32m    497\u001b[0m         X,\n\u001b[1;32m    498\u001b[0m         y,\n\u001b[1;32m    499\u001b[0m         sample_weight,\n\u001b[1;32m    500\u001b[0m         i,\n\u001b[1;32m    501\u001b[0m         \u001b[38;5;28mlen\u001b[39m(trees),\n\u001b[1;32m    502\u001b[0m         verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose,\n\u001b[1;32m    503\u001b[0m         class_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclass_weight,\n\u001b[1;32m    504\u001b[0m         n_samples_bootstrap\u001b[38;5;241m=\u001b[39mn_samples_bootstrap,\n\u001b[1;32m    505\u001b[0m         missing_values_in_feature_mask\u001b[38;5;241m=\u001b[39mmissing_values_in_feature_mask,\n\u001b[1;32m    506\u001b[0m     )\n\u001b[1;32m    507\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(trees)\n\u001b[1;32m    508\u001b[0m )\n\u001b[1;32m    510\u001b[0m \u001b[38;5;66;03m# Collect newly grown trees\u001b[39;00m\n\u001b[1;32m    511\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_\u001b[38;5;241m.\u001b[39mextend(trees)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/sklearn/utils/parallel.py:74\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     69\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     70\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     71\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     73\u001b[0m )\n\u001b[0;32m---> 74\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/joblib/parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[1;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[1;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[1;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[1;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/joblib/parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[1;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[1;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[1;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[1;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[1;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[1;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/joblib/parallel.py:1762\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m   1760\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[1;32m   1761\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[0;32m-> 1762\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m0.01\u001b[39m)\n\u001b[1;32m   1763\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[1;32m   1766\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[1;32m   1767\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Apply SMOTE to the training data\n",
    "print(\"Applying SMOTE oversampling...\")\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Check class distribution after SMOTE\n",
    "print(f\"Class distribution after SMOTE:\")\n",
    "print(f\"Class 0 (no request): {sum(y_train_smote == 0)}\")\n",
    "print(f\"Class 1 (request): {sum(y_train_smote == 1)}\")\n",
    "print(f\"Ratio: {sum(y_train_smote == 1)/len(y_train_smote):.2f}\")\n",
    "\n",
    "# Train Random Forest on SMOTE-resampled data\n",
    "print(\"\\nTraining RF with SMOTE data...\")\n",
    "rf_smote = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    "    # No class_weight needed since SMOTE already balanced the classes\n",
    ")\n",
    "rf_smote.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_smote = rf_smote.predict(X_test)\n",
    "y_pred_proba_smote = rf_smote.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Evaluate model\n",
    "smote_accuracy = accuracy_score(y_test, y_pred_smote)\n",
    "smote_precision, smote_recall, smote_f1, _ = precision_recall_fscore_support(\n",
    "    y_test, y_pred_smote, average='binary'\n",
    ")\n",
    "\n",
    "print(f\"RF+SMOTE Performance:\")\n",
    "print(f\"Accuracy: {smote_accuracy:.4f}\")\n",
    "print(f\"Precision: {smote_precision:.4f}\")\n",
    "print(f\"Recall: {smote_recall:.4f}\")\n",
    "print(f\"F1 Score: {smote_f1:.4f}\")\n",
    "\n",
    "# Sample predictions with SMOTE-trained model\n",
    "def predict_request_probability_smote(neighborhood, date_str, hour):\n",
    "    # Parse date\n",
    "    date = pd.to_datetime(date_str)\n",
    "    \n",
    "    # Create feature row\n",
    "    features = {\n",
    "        'hour': hour,\n",
    "        'day_of_week': date.dayofweek,\n",
    "        'month': date.month,\n",
    "        'is_weekend': 1 if date.dayofweek >= 5 else 0,\n",
    "        'season': 0 if date.month in [12, 1, 2] else \n",
    "                 1 if date.month in [3, 4, 5] else\n",
    "                 2 if date.month in [6, 7, 8] else 3\n",
    "    }\n",
    "    \n",
    "    # Add neighborhood one-hot encoding\n",
    "    for col in neighborhoods_encoded.columns:\n",
    "        features[col] = 1 if col == f'neighborhood_{neighborhood}' else 0\n",
    "    \n",
    "    # Create DataFrame with single row\n",
    "    sample = pd.DataFrame([features])\n",
    "    \n",
    "    # Get columns in right order\n",
    "    sample = sample[X.columns]\n",
    "    \n",
    "    # Predict\n",
    "    return rf_smote.predict_proba(sample)[0][1]\n",
    "\n",
    "print(\"\\nSample Predictions with RF+SMOTE:\")\n",
    "print(f\"Probability of request in Downtown tomorrow at 8am: {predict_request_probability_smote('Central Business District', '2023-04-01', 8):.4f}\")\n",
    "print(f\"Probability of request in South Side Flats on weekend at 11pm: {predict_request_probability_smote('South Side Flats', '2023-04-02', 23):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Regressor:\n",
      "RMSE: 1.7766\n",
      "MAE: 0.7891\n",
      "\n",
      "Poisson Regressor:\n",
      "RMSE: 1.6913\n",
      "MAE: 0.7988\n"
     ]
    }
   ],
   "source": [
    "# Convert to count-based approach\n",
    "request_counts = df.groupby(['date', 'hour', 'neighborhood']).size().reset_index(name='request_count')\n",
    "\n",
    "# Feature engineering (same as before)\n",
    "request_counts['date'] = pd.to_datetime(request_counts['date'])\n",
    "request_counts['day_of_week'] = request_counts['date'].dt.dayofweek\n",
    "request_counts['month'] = request_counts['date'].dt.month\n",
    "request_counts['is_weekend'] = request_counts['day_of_week'].apply(lambda x: 1 if x >= 5 else 0)\n",
    "request_counts['season'] = request_counts['month'].apply(lambda x: \n",
    "                                                   0 if x in [12, 1, 2] else  # Winter\n",
    "                                                   1 if x in [3, 4, 5] else   # Spring\n",
    "                                                   2 if x in [6, 7, 8] else   # Summer\n",
    "                                                   3)                         # Fall\n",
    "\n",
    "# One-hot encode neighborhoods\n",
    "neighborhoods_encoded = pd.get_dummies(request_counts['neighborhood'], prefix='neighborhood')\n",
    "\n",
    "# Prepare features\n",
    "X = pd.concat([\n",
    "    request_counts[['hour', 'day_of_week', 'month', 'is_weekend', 'season']],\n",
    "    neighborhoods_encoded\n",
    "], axis=1)\n",
    "\n",
    "y = request_counts['request_count']\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Option 1: Random Forest Regressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rf_reg = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf_reg.fit(X_train, y_train)\n",
    "\n",
    "# Option 2: Poisson Regression (specifically for count data)\n",
    "from sklearn.linear_model import PoissonRegressor\n",
    "poisson_model = PoissonRegressor(alpha=0.1)\n",
    "poisson_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "rf_preds = rf_reg.predict(X_test)\n",
    "poisson_preds = poisson_model.predict(X_test)\n",
    "\n",
    "print(\"Random Forest Regressor:\")\n",
    "print(f\"RMSE: {np.sqrt(mean_squared_error(y_test, rf_preds)):.4f}\")\n",
    "print(f\"MAE: {mean_absolute_error(y_test, rf_preds):.4f}\")\n",
    "\n",
    "print(\"\\nPoisson Regressor:\")\n",
    "print(f\"RMSE: {np.sqrt(mean_squared_error(y_test, poisson_preds)):.4f}\")\n",
    "print(f\"MAE: {mean_absolute_error(y_test, poisson_preds):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample Random Forest Predictions:\n",
      "Expected requests in Downtown (8am): 1.03\n",
      "Expected requests in South Side Flats (11pm): 1.61\n",
      "Expected requests in Squirrel Hill South (2pm): 1.63\n",
      "Expected requests in Brookline (9am): 1.00\n",
      "\n",
      "Actual vs Predicted for some test samples:\n",
      "Neighborhood: Lincoln Place, Hour: 8\n",
      "  Actual: 1.0, RF: 1.5, Poisson: 1.6\n",
      "Neighborhood: Brookline, Hour: 6\n",
      "  Actual: 2.0, RF: 1.3, Poisson: 1.8\n",
      "Neighborhood: Squirrel Hill South, Hour: 15\n",
      "  Actual: 1.0, RF: 1.1, Poisson: 1.6\n",
      "Neighborhood: Spring Garden, Hour: 15\n",
      "  Actual: 1.0, RF: 1.2, Poisson: 1.5\n",
      "Neighborhood: South Oakland, Hour: 15\n",
      "  Actual: 1.0, RF: 1.0, Poisson: 1.6\n"
     ]
    }
   ],
   "source": [
    "# Sample predictions with Random Forest\n",
    "print(\"\\nSample Random Forest Predictions:\")\n",
    "# Create a function similar to before\n",
    "def predict_request_count(model, neighborhood, date_str, hour):\n",
    "    date = pd.to_datetime(date_str)\n",
    "    features = {\n",
    "        'hour': hour,\n",
    "        'day_of_week': date.dayofweek,\n",
    "        'month': date.month,\n",
    "        'is_weekend': 1 if date.dayofweek >= 5 else 0,\n",
    "        'season': 0 if date.month in [12, 1, 2] else \n",
    "                 1 if date.month in [3, 4, 5] else\n",
    "                 2 if date.month in [6, 7, 8] else 3\n",
    "    }\n",
    "    \n",
    "    # Add neighborhood encoding\n",
    "    for col in neighborhoods_encoded.columns:\n",
    "        features[col] = 1 if col == f'neighborhood_{neighborhood}' else 0\n",
    "    \n",
    "    sample = pd.DataFrame([features])\n",
    "    sample = sample[X.columns]\n",
    "    \n",
    "    return model.predict(sample)[0]\n",
    "\n",
    "# Show predictions for popular neighborhoods at different times\n",
    "print(f\"Expected requests in Downtown (8am): {predict_request_count(rf_reg, 'Central Business District', '2023-04-01', 8):.2f}\")\n",
    "print(f\"Expected requests in South Side Flats (11pm): {predict_request_count(rf_reg, 'South Side Flats', '2023-04-01', 23):.2f}\")\n",
    "print(f\"Expected requests in Squirrel Hill South (2pm): {predict_request_count(rf_reg, 'Squirrel Hill South', '2023-04-01', 14):.2f}\")\n",
    "print(f\"Expected requests in Brookline (9am): {predict_request_count(rf_reg, 'Brookline', '2023-04-01', 9):.2f}\")\n",
    "\n",
    "# Compare with actual counts from test data\n",
    "print(\"\\nActual vs Predicted for some test samples:\")\n",
    "sample_indices = np.random.choice(len(X_test), 5, replace=False)\n",
    "for idx in sample_indices:\n",
    "    actual = y_test.iloc[idx]\n",
    "    predicted_rf = rf_preds[idx]\n",
    "    predicted_poisson = poisson_preds[idx]\n",
    "    \n",
    "    # Get neighborhood name (need to reverse the one-hot encoding)\n",
    "    neighborhood_cols = [col for col in X_test.columns if col.startswith('neighborhood_')]\n",
    "    neighborhood_idx = np.argmax(X_test.iloc[idx][neighborhood_cols])\n",
    "    neighborhood = neighborhood_cols[neighborhood_idx].replace('neighborhood_', '')\n",
    "    \n",
    "    hour = X_test.iloc[idx]['hour']\n",
    "    \n",
    "    print(f\"Neighborhood: {neighborhood}, Hour: {int(hour)}\")\n",
    "    print(f\"  Actual: {actual:.1f}, RF: {predicted_rf:.1f}, Poisson: {predicted_poisson:.1f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
